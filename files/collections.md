### Collections Framework

### Полезные ссылки  

[Habr - Хитрые вопросы. Java собеседование. Коллекции](https://habr.com/ru/articles/162017/)  
[Habr - Накладные расходы памяти у коллекций](https://habr.com/ru/articles/159557/)  
[Справочник по Java Collections Framework](https://habr.com/ru/articles/237043/)  
[Habr - Внутренняя работа HashMap в Java](https://habr.com/ru/articles/421179/)  
[Особенности TreeMap в Java](https://javarush.com/groups/posts/2584-osobennosti-treemap)  

![Сложность-lists](/images/lists.jpg)  

![Сложность-maps](/images/maps.jpg)  

## Array - Массив  

* Размер массива постоянен
* Увеличение длины только через новый экземпляр или копирование Arrays.copyOf()
* Поиск работает только на отсортированном массиве Arrays.binarySearch()
* Удаление элемента очищает значение, но индекс с null остается
* После создания массива с помощью new, в его ячейках записаны значения по умолчанию.  
  **_Для численных типов это будет 0_**  
  **_Для boolean — false_**  
  **_Для ссылочных типов — null_**  
* Многомерные массивы Int[][] myTwoDimensionalArray = new int [8][8]

## Set - Множество  

Iterable (interface)  
    Collection (interface)
- Set (interface)
    - HashSet
        - LinkedHashSet
    - SortedSet (interface)
        - NavigableSet (interface)
            - TreeSet

**_Sets:_**  
* **_HashSet_**
* **_LinkedHashSet_**
* **_TreeSet_**  

### HashSet  
* Основан на HashMap
* Фактически хранит ключи HashMap, в значении лежит new Object()
* Как и любой set хранит только уникальные элементы
* Так же как и HashMap позволяет хранить null, но только один
* Не синхронизирован, для синхронизации рекомендуется использовать Collections.synchronizedSet(new HashSet<>())
* Порядок элементов не гарантирован, как и в Map.
* Операции add, remove, contains and size выполняются за константное время O(1)
* Реализует Fail-fast т.е. выкидывает ConcurrentModificationException при конкурентной модификации (модификация до вызова next())  

### LinkedHashSet  
* Имплементация на основе HashSet(HashMap) и связанного списка
* Гарантирует порядок итерирования как 'порядок вставки'
* Повторное добавление элементов сохраняет порядок итерирования
* Гарантирует порядок при создании копии new LinkedHashSet(set)
* Как и HashSet операции add, remove, contains and size выполняются за константное время O(1)  

### NavigableSet (interface)  
- Есть методы навигации больше (или равно) меньше (или равно)
- Есть методы выстроить множество в обратном порядке
- Обратный итератор
- получить подмножество с конца или начала

### TreeSet  
* Основан на TreeMap, т.е. бинарном дереве (красно-черное дерево)
* Фактически хранит ключи TreeMap, в значении лежит new Object()
* Изначально отсортирован естественный порядок (natural ordering) (Реализованный в Comparable метод сравнения)
* Или через Comparator, объявленный при создании коллекции
* Гарантированное логарифмическое log(n) время базовых операций add, remove, contains
* Не синхронизирован, для синхронизации рекомендуется использовать Collections.synchronizedSet(new HashSet<>())

## List - Список  

Iterable (interface)  
Collection (interface)  
- List (interface)
    - ArrayList
    - LinkedList
    - Vector
    - Stack
- Queue (interface)
    - Deque
    - LinkedList

**_List:_**
* **_ArrayList_**
* **_LinkedList_**
* **_Vector_**
* **_Stack_**

### ArrayList
* Основан на Array
* Размер списка может меняться в отличие от Array
* Начальная емкость списка (capacity) 10
* Автоматически увеличивает длину списка в полтора раза при достижении порогового значения
* Автоматически не уменьшает размер, для этого надо использовать метод trimToSize()
* При добавлении/удалении элементов список сдвигается вправо/влево
* Операции size, isEmpty, get, set, iterator выполняются за константное время О(1)
* Добавление нового элемента за линейное О(n)
* Не синхронизирован,  для синхронизации рекомендуется использовать Collections.synchronizedList(new ArrayList<>())  

### Queue (interface)  
* Коллекция предназначенная для последовательной обработки элементов
* Реализует принцип FIFO (первый вошел - первый вышел)
* Новые элементы добавляются в конец очереди FIFO
* Null не рекомендуется добавлять в очередь т.к. метод poll() возвращает null и можно запутаться
* содержит набор методов для отбора/просмотра элементов  

|             | Insert    | Remove    | Examine    |
|-------------|-----------|-----------|------------|
| Collections | add(e)    | remove(e) | element()  |
| Queue       | offer(e)  |   poll()  |  peek()    |   
* Есть имплементация PriorityQueue, которая сортируется через Comparator

### Deque (interface)  
* Deque "double ended queue" - очередь с двумя концами
* Так же может быть использована как LIFO (методом offer() / addFirst() добавляем в начало очереди и читаем последний элемент методом pollLast())
* Нет доступа к элементам по индексу  

### LinkedList  
* Имплементация List и Deque
* Реализует двусвязанный список
* Реализует Fail-fast т.е. выкидывает ConcurrentModificationException при конкурентной модификации (модификация до вызова next())
* Может итерироваться в обе стороны  

### Vector/Stack  
Синхронизированы, но не полностью, устарели

## Map - ключ - значение

- Map (interface)
    - HashTable
    - HashMap
    - LinkedHashMap
    - SortedMap (interface)
        - NavigatableMap (interface)
            - TreeMap

**_Map:_**
* **_HashMap_**
* **_LinkedHashMap_**
* **_TreeMap_**

**_Коллизия - когда у двух объектов одного типа одинаковый hash, в таком случае элемент массива преобразуется в связанный список._**

### HashMap  
* Основан на bucket'ах (корзинах), фактически это array
* Корзина - элемент массива table
* Начальный размер initial capacity равен 16
* На производительность влияют 2 параметра initial capacity (16) and load factor (0.75)
* initial capacity - начальная ёмкость массива table (количество корзин)
* load factor - число определяющее пороговое значения для увеличения длины массива table
* Как только достигается load factor длина массива table увеличивается в 2 раза (32)
* Так же в этот момент происходит перехеширование / пересоздание table
* Реализует Fail-fast т.е. выкидывает ConcurrentModificationException при конкурентной модификации
* Сложность операций get() и put() практически константна до тех пор, пока не будет проведено повторное хеширование
* TREEIFY_THRESHOLD = 8 при достижении 8 элементов в одной корзине, вложенная структура данных меняется на TreeNode
* MIN_TREEIFY_CAPACITY = 64 минимальная емкость (количество корзин) хеш-таблицы, при которой возможен переход к древовидной структуре.
Т.е. если в хеш-таблице по крайней мере 64 бакета и в одном бакете 8 или более элементов, то произойдет переход к древовидной структуре.

**_Корзина_**, она же бакет, table состоит из **_Узлов (Node)_**, который содержит:    
* **_int — хэш_**
* **_K — ключ_**
* **_V — значение_**
* **_Node — ссылка на следующий элемент_**  

**_Два или более узла могут иметь один и тот-же bucket. В этом случае для связи узлов используется структура данных связанный список._**

#### Вычисление индекса в HashMap
index = hashCode(key) & (n-1).  
где n равна числу bucket или значению длины массива

#### Как работает метод put  
1. Вычислить значение hash ключа
2. Вычислить индекс с помощью метода index
3. Создать объект node.
4. Поместить объект node в позицию с индексом, если место свободно.  

#### Как работает метод put с коллизией  
1. Вычислить значение hash ключа
2. Вычислить индекс с помощью метода index
3. Создать объект node.
4. Поместить объект node в позицию с индексом, если место свободно. (**_место занято - это есть корллизия!!!_**)
5. В данном случае в позиции с индексом уже существует другой объект, этот случай называется коллизией.
6. В таком случае проверяем с помощью методов hashCode() и equals(), что оба ключа одинаковы.
   - **_Если ключи одинаковы, заменить текущее значение новым._**
   - **_Иначе связать новый и старый объекты с помощью структуры данных **_"связанный список", указав ссылку на следующий объект в текущем и сохранить оба под этим индексом._**

#### Как работает метод get  
1. Вычислить hash ключа
2. Вычислить индекс с помощью метода index
3. Перейти по индексу и сравнить ключ первого элемента с имеющемся значением.
    - **_Если они равны - вернуть значение_**
    - **_Иначе выполнить проверку для следующего элемента, если он существует._**

### LinkedHashMap  
* Имплементация на основе HashMap и связанного списка
* Гарантирует порядок итерирования как 'порядок вставки'
* Повторное добавление элементов сохраняет порядок итерирования
* Создание копии - new LinkedHashMap(m) гарантирует 'порядок вставки'
* access-order

### TreeMap  
Самая важная особенность красно-чёрного дерева в том, что оно умеет само себя балансировать, поэтому не важно в каком порядке будут добавляться в него элементы, преимущества этой структуры данных будут сохраняться. Сбалансированность достигается за счёт поддержания правил красно-чёрной раскраски вершин:  
**_Вариант 1:_**  
* Вершина может быть либо красной, либо чёрной и имеет двух потомков
* Красная вершина не может быть дочерней для красной вершины
* Количество чёрных вершин от корня до листа включительно одинаково для любого листа
* Корень дерева является чёрным
* Все листья — чёрные и не содержат данных  

**_Вариант 2:_**  
* Корень должен быть окрашен в черный цвет.
* Листья дерева должны быть черного цвета.
* Красный узел должен иметь два черных дочерних узла.
* Черный узел может иметь любые дочерние узлы.
* Путь от узла к его листьям должен содержать одинаковое количество черных узлов.
* Новые узлы добавляются на места листьев.
